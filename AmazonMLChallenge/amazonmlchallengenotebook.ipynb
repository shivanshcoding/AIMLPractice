{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-11T11:12:54.573809Z","iopub.execute_input":"2026-01-11T11:12:54.574094Z","iopub.status.idle":"2026-01-11T11:12:54.871517Z","shell.execute_reply.started":"2026-01-11T11:12:54.574063Z","shell.execute_reply":"2026-01-11T11:12:54.870798Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/amazon-ml-challenge/sample_test.csv\n/kaggle/input/amazon-ml-challenge/sample_test_out.csv\n/kaggle/input/amazon-ml-challenge/evaluation.py\n/kaggle/input/amazon-ml-challenge/train.csv\n/kaggle/input/amazon-ml-challenge/test.csv\n/kaggle/input/models/pytorch/models-by-shivansh/1/lgbm_regressor.pkl\n/kaggle/input/models/pytorch/models-by-shivansh/1/price_processor.joblib\n/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/config.json\n/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/merges.txt\n/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/training_args.bin\n/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/vocab.json\n/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/tokenizer_config.json\n/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/model.safetensors\n/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/special_tokens_map.json\n/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-1172/config.json\n/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-1172/trainer_state.json\n/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-1172/training_args.bin\n/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-1172/scaler.pt\n/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-1172/scheduler.pt\n/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-1172/model.safetensors\n/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-1172/optimizer.pt\n/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-1172/rng_state.pth\n/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-2344/config.json\n/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-2344/trainer_state.json\n/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-2344/training_args.bin\n/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-2344/scaler.pt\n/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-2344/scheduler.pt\n/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-2344/model.safetensors\n/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-2344/optimizer.pt\n/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-2344/rng_state.pth\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import scipy, transformers, accelerate, sklearn, joblib, re, os\nfrom scipy import stats\nfrom scipy.stats.mstats import winsorize\nimport lightgbm as lgb\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T11:29:50.956641Z","iopub.execute_input":"2026-01-11T11:29:50.957002Z","iopub.status.idle":"2026-01-11T11:29:54.264949Z","shell.execute_reply.started":"2026-01-11T11:29:50.956974Z","shell.execute_reply":"2026-01-11T11:29:54.264381Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"import shutil\nimport os\n\nSRC_MODEL_DIR = \"/kaggle/input/models/pytorch/models-by-shivansh/1\"\nDST_MODEL_DIR = \"/kaggle/working/models\"\n\nos.makedirs(DST_MODEL_DIR, exist_ok=True)\n\nfor item in os.listdir(SRC_MODEL_DIR):\n    src = os.path.join(SRC_MODEL_DIR, item)\n    dst = os.path.join(DST_MODEL_DIR, item)\n\n    if os.path.isdir(src):\n        shutil.copytree(src, dst, dirs_exist_ok=True)\n    else:\n        shutil.copy2(src, dst)\n\nprint(\"笨 Models copied to writable directory\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T11:26:01.979472Z","iopub.execute_input":"2026-01-11T11:26:01.980257Z","iopub.status.idle":"2026-01-11T11:26:32.565982Z","shell.execute_reply.started":"2026-01-11T11:26:01.980223Z","shell.execute_reply":"2026-01-11T11:26:32.565202Z"}},"outputs":[{"name":"stdout","text":"笨 Models copied to writable directory\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"!pip uninstall -y torch torchvision torchaudio\n!pip install torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 \\\n  --index-url https://download.pytorch.org/whl/cu121\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T11:13:38.844654Z","iopub.execute_input":"2026-01-11T11:13:38.845413Z","iopub.status.idle":"2026-01-11T11:16:11.843921Z","shell.execute_reply.started":"2026-01-11T11:13:38.845387Z","shell.execute_reply":"2026-01-11T11:16:11.843118Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: torch 2.8.0+cu126\nUninstalling torch-2.8.0+cu126:\n  Successfully uninstalled torch-2.8.0+cu126\nFound existing installation: torchvision 0.23.0+cu126\nUninstalling torchvision-0.23.0+cu126:\n  Successfully uninstalled torchvision-0.23.0+cu126\nFound existing installation: torchaudio 2.8.0+cu126\nUninstalling torchaudio-2.8.0+cu126:\n  Successfully uninstalled torchaudio-2.8.0+cu126\nLooking in indexes: https://download.pytorch.org/whl/cu121\nCollecting torch==2.2.2\n  Downloading https://download.pytorch.org/whl/cu121/torch-2.2.2%2Bcu121-cp312-cp312-linux_x86_64.whl (757.2 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m757.2/757.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torchvision==0.17.2\n  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.17.2%2Bcu121-cp312-cp312-linux_x86_64.whl (7.0 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hCollecting torchaudio==2.2.2\n  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.2.2%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (3.20.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (4.15.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (2025.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m117.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.17.2) (2.0.2)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.17.2) (11.3.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2) (12.6.85)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.2.2) (3.0.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.2.2) (1.3.0)\nInstalling collected packages: nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.6.77\n    Uninstalling nvidia-nvtx-cu12-12.6.77:\n      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.27.3\n    Uninstalling nvidia-nccl-cu12-2.27.3:\n      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.7.77\n    Uninstalling nvidia-curand-cu12-10.3.7.77:\n      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.2+cu121 torchaudio-2.2.2+cu121 torchvision-0.17.2+cu121\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nprint(torch.__version__)\nprint(torch.version.cuda)\nprint(torch.cuda.is_available())\nprint(torch.cuda.get_device_name(0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T11:16:11.845257Z","iopub.execute_input":"2026-01-11T11:16:11.845544Z","iopub.status.idle":"2026-01-11T11:16:11.850708Z","shell.execute_reply.started":"2026-01-11T11:16:11.845515Z","shell.execute_reply":"2026-01-11T11:16:11.849968Z"}},"outputs":[{"name":"stdout","text":"2.8.0+cu126\n12.6\nTrue\nTesla P100-PCIE-16GB\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"**Configuration**","metadata":{}},{"cell_type":"code","source":"# --- File Paths ---\nDATA_DIR = \"/kaggle/input/amazon-ml-challenge/\"\nTRAIN_FILE = f\"{DATA_DIR}train.csv\"\nTEST_FILE = f\"{DATA_DIR}test.csv\"\nMODEL_DIR = \"/kaggle/working/models/\"\nSUBMISSION_FILE = \"/kaggle/working/submission.csv\"\n\n# --- Preprocessing ---\nPRICE_COLUMN = \"price\"\nTEXT_COLUMN = \"catalog_content\"\nTARGET_CLASS_COLUMN = \"price_class\"\nNUM_PRICE_CLASSES = 14\n\n# --- RoBERTa Model ---\nROBERTA_MODEL_NAME = \"roberta-base\"\nROBERTA_MODEL_PATH = f\"{MODEL_DIR}roberta_classifier\"\nROBERTA_BATCH_SIZE = 64      # Increased for speed\nROBERTA_EPOCHS = 2           # Reduced, often sufficient\nROBERTA_LEARNING_RATE = 2e-5\n\n# --- Ensemble Model (LightGBM) ---\nENSEMBLE_MODEL_PATH = f\"{MODEL_DIR}lgbm_regressor.pkl\"\nLGBM_PARAMS = {\n    'objective': 'regression_l1', 'metric': 'mae', 'n_estimators': 2000,\n    'learning_rate': 0.01, 'feature_fraction': 0.8, 'bagging_fraction': 0.8,\n    'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.1,\n    'num_leaves': 31, 'verbose': -1, 'n_jobs': -1,\n}\n\n# --- General ---\nRANDOM_STATE = 42\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T11:27:43.071000Z","iopub.execute_input":"2026-01-11T11:27:43.071586Z","iopub.status.idle":"2026-01-11T11:27:43.076814Z","shell.execute_reply.started":"2026-01-11T11:27:43.071556Z","shell.execute_reply":"2026-01-11T11:27:43.076179Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"**Data PreProcessing**","metadata":{}},{"cell_type":"code","source":"# ----------------- Feature Engineering (from your provided code) -----------------\nweight_units = {'g','gram','grams','gramm','gr','kg','k','lb','pound','pounds','oz','ounce','ounces'}\nvolume_units = {'ml','millilitre','milliliter','mililitro','ltr','liter','liters','l','fl oz','fluid ounce','fluid ounces','fluid ounces'}\ncount_units  = {'count','ct','each','unit','units','pack','packs','piece','pieces','box','bottle','bottles','bag','bags','case','carton','capsule','jar','pouch','bucket','tea bags','paper cupcake liners'}\nlength_units = {'cm','mm','m','meter','meters','inch','inches','in','ft','foot','feet'}\n\ndef extract_value_unit(text):\n    lines = [l.strip() for l in str(text).split(\"\\n\") if l.strip()]\n    if len(lines) < 2:\n        return pd.Series([None, None])\n    value_line = lines[-2]\n    unit_line = lines[-1]\n    match_val = re.search(r\"[\\d\\.]+\", value_line)\n    value = float(match_val.group()) if match_val else None\n    unit = re.sub(r'Unit[s]?:\\s*', '', unit_line, flags=re.IGNORECASE).strip()\n    return pd.Series([value, unit])\n\ndef extract_ipq(text):\n    patterns = [r'pack of (\\d+)', r'(\\d+)\\s*count', r'box of (\\d+)', r'case of (\\d+)', r'(\\d+)\\s*pieces', r'(\\d+)\\s*units', r'(\\d+)\\s*ct', r'(\\d+)\\s*each']\n    text_lower = str(text).lower()\n    for pat in patterns:\n        match = re.search(pat, text_lower)\n        if match:\n            return int(match.group(1))\n    return 1\n\ndef map_unit_class(unit):\n    if unit is None: return 'others'\n    u = unit.strip().lower()\n    if u in weight_units: return 'weight'\n    if u in volume_units: return 'volume'\n    if u in count_units: return 'count'\n    if u in length_units: return 'length'\n    return 'others'\n\ndef convert_to_standard(value, unit):\n    if value is None or unit is None: return value\n    u = unit.strip().lower()\n    if u in {'oz', 'ounce', 'ounces'}: return value * 28.3495\n    if u in {'lb', 'pound', 'pounds'}: return value * 453.592\n    if u in {'kg', 'k'}: return value * 1000\n    if u in {'g', 'gram', 'grams', 'gramm', 'gr'}: return value\n    if u in {'ltr', 'liter', 'liters', 'l'}: return value * 1000\n    if u in {'fl oz', 'fluid ounce', 'fluid ounces'}: return value * 29.5735\n    if u in {'ml', 'millilitre', 'milliliter', 'mililitro'}: return value\n    if u in {'cm'}: return value / 100\n    if u in {'mm'}: return value / 1000\n    if u in {'inch', 'inches', 'in'}: return value * 0.0254\n    if u in {'ft', 'foot', 'feet'}: return value * 0.3048\n    if u in {'m', 'meter', 'meters'}: return value\n    if u in count_units: return value\n    return value\n\ndef engineer_features(df):\n    \"\"\"Applies all feature engineering steps.\"\"\"\n    temp_df = df.copy()\n    temp_df[['value', 'unit']] = temp_df['catalog_content'].apply(extract_value_unit)\n    temp_df['IPQ'] = temp_df['catalog_content'].apply(extract_ipq)\n    temp_df['standardised_units'] = temp_df['unit'].apply(map_unit_class)\n    temp_df['updated_values'] = temp_df.apply(lambda row: convert_to_standard(row['value'], row['unit']), axis=1)\n    \n    # Fill NaNs created during feature engineering\n    temp_df['updated_values'] = temp_df['updated_values'].fillna(temp_df['updated_values'].median())\n    temp_df['IPQ'] = temp_df['IPQ'].fillna(1)\n    \n    # One-hot encode and ensure all possible columns are present\n    unit_dummies = pd.get_dummies(temp_df['standardised_units'], prefix='unit')\n    for col in ['unit_weight', 'unit_volume', 'unit_count', 'unit_length', 'unit_others']:\n        if col not in unit_dummies.columns:\n            unit_dummies[col] = 0\n    temp_df = pd.concat([temp_df, unit_dummies], axis=1)\n    \n    return temp_df\n\n# ----------------- Price Transformation Pipeline -----------------\n\nclass PriceProcessor:\n    \"\"\"Handles Box-Cox, Winsorization, and Binning for the price column.\"\"\"\n    def __init__(self):\n        self.lambda_ = None\n        self.winsor_limits = (0.01, 0.01) # Winsorize 1% from both tails\n        self.bin_edges = None\n        self.path = os.path.join(MODEL_DIR, \"price_processor.joblib\")\n\n    def fit_transform(self, price_series):\n        # 1. Box-Cox Transform (add 1 to handle prices <= 0)\n        transformed_price, self.lambda_ = stats.boxcox(price_series + 1)\n        \n        # 2. Winsorization\n        winsorized_price = winsorize(transformed_price, limits=self.winsor_limits)\n        \n        # 3. Binning into classes\n        binned_price, self.bin_edges = pd.qcut(\n            winsorized_price, \n            q=NUM_PRICE_CLASSES, \n            labels=False, \n            retbins=True, \n            duplicates='drop'\n        )\n        self.save()\n        return binned_price\n\n    def save(self):\n        os.makedirs(os.path.dirname(self.path), exist_ok=True)\n        joblib.dump(self, self.path)\n\n    @classmethod\n    def load(cls):\n        return joblib.load(os.path.join(MODEL_DIR, \"price_processor.joblib\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T11:27:45.581453Z","iopub.execute_input":"2026-01-11T11:27:45.582188Z","iopub.status.idle":"2026-01-11T11:27:45.597753Z","shell.execute_reply.started":"2026-01-11T11:27:45.582157Z","shell.execute_reply":"2026-01-11T11:27:45.597108Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"**Ensemble Model**","metadata":{}},{"cell_type":"code","source":"def get_feature_columns(df):\n    \"\"\"Identifies the feature columns for the ensemble model.\"\"\"\n    # Exclude identifiers, raw text, and the original target\n    exclude_cols = [\n        'sample_id', 'catalog_content', 'image_links', 'price',\n        'price_class', 'value', 'unit', 'standardised_units'\n    ]\n    feature_cols = [col for col in df.columns if col not in exclude_cols]\n    return feature_cols\n\ndef train_ensemble_model(df, target_col):\n    \"\"\"Trains and saves the Voting Regressor model (SVR + DecisionTree + AdaBoost).\"\"\"\n    feature_cols = get_feature_columns(df)\n    X_train = df[feature_cols]\n    y_train = df[target_col]\n\n    # Base learners\n    svr = make_pipeline(StandardScaler(), SVR(**SVM_PARAMS))\n    dtr = DecisionTreeRegressor(random_state=RANDOM_STATE, **DT_PARAMS)\n    ada = AdaBoostRegressor(random_state=RANDOM_STATE, **ADABOOST_PARAMS)\n\n    # Voting ensemble\n    model = VotingRegressor(\n        estimators=[\n            (\"svr\", svr),\n            (\"dt\", dtr),\n            (\"ada\", ada),\n        ],\n        weights=VOTING_WEIGHTS,\n        n_jobs=None,  # VotingRegressor in sklearn doesn't support n_jobs (only in some versions for estimators); keep None\n    )\n\n    model.fit(X_train, y_train)\n\n    # Save the model\n    os.makedirs(os.path.dirname(ENSEMBLE_MODEL_PATH), exist_ok=True)\n    joblib.dump(model, ENSEMBLE_MODEL_PATH)\n    print(f\"Ensemble model saved to {ENSEMBLE_MODEL_PATH}\")\n    return model\n\ndef predict_with_ensemble_model(df):\n    \"\"\"Loads and predicts with the saved Voting Regressor model.\"\"\"\n    feature_cols = get_feature_columns(df)\n    X_test = df[feature_cols]\n\n    model = joblib.load(ENSEMBLE_MODEL_PATH)\n    predictions = model.predict(X_test)\n    return predictions\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T11:27:49.753106Z","iopub.execute_input":"2026-01-11T11:27:49.753807Z","iopub.status.idle":"2026-01-11T11:27:49.760493Z","shell.execute_reply.started":"2026-01-11T11:27:49.753776Z","shell.execute_reply":"2026-01-11T11:27:49.759754Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"**Evaluation**","metadata":{}},{"cell_type":"code","source":"def smape(y_true, y_pred):\n    # Calculates the Symmetric Mean Absolute Percentage Error (SMAPE).\n    numerator = np.abs(y_pred - y_true)\n    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n    \n    # Handle the case where both true and pred are zero\n    # to avoid division by zero\n    ratio = np.where(denominator == 0, 0, numerator / denominator)\n    \n    return np.mean(ratio) * 100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T11:27:52.891142Z","iopub.execute_input":"2026-01-11T11:27:52.891476Z","iopub.status.idle":"2026-01-11T11:27:52.895672Z","shell.execute_reply.started":"2026-01-11T11:27:52.891448Z","shell.execute_reply":"2026-01-11T11:27:52.895074Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"**Roberta Classifier**","metadata":{}},{"cell_type":"code","source":"class PriceDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len=128):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        text = str(self.texts[item])\n        label = self.labels[item]\n\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            return_token_type_ids=False,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }\n\ndef train_roberta(train_df, text_col, target_col):\n    \"\"\"Fine-tunes and saves the RoBERTa model.\"\"\"\n    tokenizer = RobertaTokenizer.from_pretrained(ROBERTA_MODEL_NAME)\n    model = RobertaForSequenceClassification.from_pretrained(\n        ROBERTA_MODEL_NAME,\n        num_labels=train_df[target_col].nunique()\n    ).to(DEVICE)\n\n    train_dataset = PriceDataset(\n        texts=train_df[text_col].to_numpy(),\n        labels=train_df[target_col].to_numpy(),\n        tokenizer=tokenizer\n    )\n\n    training_args = TrainingArguments(\n        output_dir=ROBERTA_MODEL_PATH,\n        num_train_epochs=ROBERTA_EPOCHS,\n        per_device_train_batch_size=ROBERTA_BATCH_SIZE,\n        learning_rate=ROBERTA_LEARNING_RATE,\n        logging_dir='./logs',\n        logging_steps=100,\n        do_train=True,\n        do_eval=False,\n        save_strategy=\"epoch\",\n        fp16=True,  # Mixed-precision for speed\n        load_best_model_at_end=False,\n        seed=RANDOM_STATE,\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n    )\n\n    trainer.train()\n    trainer.save_model(ROBERTA_MODEL_PATH)\n    tokenizer.save_pretrained(ROBERTA_MODEL_PATH)\n    print(f\"RoBERTa model saved to {ROBERTA_MODEL_PATH}\")\n\ndef predict_with_roberta(df, text_col):\n    \"\"\"Loads a fine-tuned RoBERTa model and makes predictions.\"\"\"\n    tokenizer = RobertaTokenizer.from_pretrained(ROBERTA_MODEL_PATH)\n    model = RobertaForSequenceClassification.from_pretrained(ROBERTA_MODEL_PATH).to(DEVICE)\n    \n    # Create a dataset for prediction (labels are not used, so they can be dummies)\n    predict_dataset = PriceDataset(\n        texts=df[text_col].to_numpy(),\n        labels=np.zeros(len(df)),\n        tokenizer=tokenizer\n    )\n\n    trainer = Trainer(model=model)\n    predictions = trainer.predict(predict_dataset)\n    \n    # Return the class with the highest probability\n    return np.argmax(predictions.predictions, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T11:27:55.495024Z","iopub.execute_input":"2026-01-11T11:27:55.495751Z","iopub.status.idle":"2026-01-11T11:27:55.504515Z","shell.execute_reply.started":"2026-01-11T11:27:55.495715Z","shell.execute_reply":"2026-01-11T11:27:55.503761Z"}},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"**Predict**","metadata":{}},{"cell_type":"code","source":"def predict():\n    \"\"\"\n    Loads trained models to make predictions on the test set.\n    \"\"\"\n    print(\"Starting prediction pipeline...\")\n    print(f\"Using device: {DEVICE.upper()}\")\n\n    # --- 1. Check if Models Exist ---\n    roberta_path = os.path.join(config.ROBERTA_MODEL_PATH, \"config.json\")\n    ensemble_path = config.ENSEMBLE_MODEL_PATH\n\n    if not os.path.exists(roberta_path) or not os.path.exists(ensemble_path):\n        print(\"\\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n        print(\"!!! ERROR: Trained models not found.                   !!!\")\n        print(\"!!! Please run 'python -m src.main' to train models first. !!!\")\n        print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n        return\n\n    # --- 2. Load Test Data ---\n    print(f\"\\nStep 1: Loading test data from {config.TEST_FILE}...\")\n    if not os.path.exists(config.TEST_FILE):\n        print(f\"!!! ERROR: Test file not found at {config.TEST_FILE} !!!\")\n        return\n        \n    test_df = pd.read_csv(config.TEST_FILE)\n    print(f\"Loaded {len(test_df)} rows for prediction.\")\n\n    # --- 3. Feature Generation Pipeline ---\n    # Generate predictions from RoBERTa to use as a feature\n    print(\"\\nStep 2: Generating price class predictions from RoBERTa...\")\n    test_df['roberta_pred_class'] = predict_with_roberta(test_df, config.TEXT_COLUMN)\n\n    # Apply the same feature engineering steps used during training\n    print(\"\\nStep 3: Engineering features from catalog_content...\")\n    test_df_featured = engineer_features(test_df)\n    print(\"Feature engineering complete.\")\n\n    # --- 4. Make Final Predictions ---\n    print(\"\\nStep 4: Making final price predictions with the ensemble model...\")\n    predictions = predict_with_ensemble_model(test_df_featured)\n    test_df['price'] = predictions\n    print(\"Prediction complete.\")\n\n    # --- 5. Save the Output ---\n    output_df = test_df[['sample_id', 'predicted_price']]\n    output_df.to_csv(config.TEST_OUTPUT_FILE, index=False)\n    print(f\"\\n笨 Successfully saved predictions to {config.TEST_OUTPUT_FILE}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T11:27:59.120728Z","iopub.execute_input":"2026-01-11T11:27:59.121387Z","iopub.status.idle":"2026-01-11T11:27:59.127812Z","shell.execute_reply.started":"2026-01-11T11:27:59.121356Z","shell.execute_reply":"2026-01-11T11:27:59.127075Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"def get_roberta_predictions_with_cache(\n    df,\n    text_col,\n    cache_name,\n):\n    \"\"\"\n    Computes RoBERTa predictions once and caches them.\n    On reruns, loads directly from disk.\n    \"\"\"\n    CACHE_DIR = \"/kaggle/working/roberta_cache\"\n    os.makedirs(CACHE_DIR, exist_ok=True)\n\n    cache_path = os.path.join(CACHE_DIR, f\"{cache_name}.npy\")\n\n    if os.path.exists(cache_path):\n        print(f\"笨 Loading cached RoBERTa predictions from {cache_path}\")\n        return np.load(cache_path)\n\n    print(f\"泅 Running RoBERTa inference for {cache_name} (this may take time)...\")\n    preds = predict_with_roberta(df, text_col)\n\n    np.save(cache_path, preds)\n    print(f\"汳ｾ Saved RoBERTa predictions to {cache_path}\")\n\n    return preds\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T12:02:11.104690Z","iopub.execute_input":"2026-01-11T12:02:11.105422Z","iopub.status.idle":"2026-01-11T12:02:11.110908Z","shell.execute_reply.started":"2026-01-11T12:02:11.105394Z","shell.execute_reply":"2026-01-11T12:02:11.110195Z"}},"outputs":[],"execution_count":38},{"cell_type":"markdown","source":"**Main**","metadata":{}},{"cell_type":"code","source":"def main():\n    #--- 0. CRITICAL: Verify GPU is available ---\n    if not torch.cuda.is_available():\n        print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n        print(\"!!! ERROR: No CUDA-enabled GPU found !!!\")\n        print(\"!!!       Aborting training.       !!!\")\n        print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n        return\n    print(f\"PyTorch confirmed CUDA is available. Using device: {DEVICE.upper()}\")\n    \n    # --- 1. Load Data ---\n    print(\"\\nStep 1: Loading data...\")\n    train_df = pd.read_csv(TRAIN_FILE)\n    test_df = pd.read_csv(TEST_FILE)\n    print(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")\n\n    # --- 2. Preprocess Price Column for Training ---\n    print(\"\\nStep 2: Preprocessing price column for RoBERTa training...\")\n    price_processor = PriceProcessor()\n    train_df[TARGET_CLASS_COLUMN] = price_processor.fit_transform(train_df[PRICE_COLUMN])\n    print(f\"Price column transformed and binned into {train_df[TARGET_CLASS_COLUMN].nunique()} classes.\")\n\n    # --- 3. Fine-Tune RoBERTa Classifier ---\n    print(\"\\nStep 3: Fine-tuning RoBERTa for price classification...\")\n    model_config_path = os.path.join(ROBERTA_MODEL_PATH, \"config.json\")\n    if not os.path.exists(model_config_path):\n        print(\"RoBERTa model not found. Starting training...\")\n        train_roberta(train_df, TEXT_COLUMN, TARGET_CLASS_COLUMN)\n    else:\n        print(\"Found existing RoBERTa model. Skipping training.\")\n\n    # --- 4. Get RoBERTa Predictions as Features ---\n    print(\"\\nStep 4: Generating price class predictions from RoBERTa (with caching)...\")\n\n    train_df[\"roberta_pred_class\"] = get_roberta_predictions_with_cache(\n        train_df,\n        TEXT_COLUMN,\n        cache_name=\"train_roberta_preds\"\n    )\n\n    test_df[\"roberta_pred_class\"] = get_roberta_predictions_with_cache(\n        test_df,\n        TEXT_COLUMN,\n        cache_name=\"test_roberta_preds\"\n    )\n\n    print(\"笨 RoBERTa predictions added as features.\")\n\n    # --- 5. Engineer Additional Features ---\n    print(\"\\nStep 5: Engineering features from catalog_content...\")\n    train_df_featured = engineer_features(train_df)\n    test_df_featured = engineer_features(test_df)\n    print(\"Feature engineering complete.\")\n\n    # --- 6. Train Ensemble Model ---\n    print(\"\\nStep 6: Training the final LightGBM ensemble model...\")\n    train_ensemble_model(train_df_featured, PRICE_COLUMN)\n\n    # --- 7. Make Final Price Predictions ---\n    print(\"\\nStep 7: Making final price predictions on the test set...\")\n    test_predictions = predict_with_ensemble_model(test_df_featured)\n    test_df['price'] = test_predictions\n\n    # --- 8. Save Results ---\n    # The evaluation step has been removed as test.csv does not have a 'price' column.\n    print(\"\\nStep 8: Saving submission file...\")\n    submission_df = test_df[['sample_id', 'price']]\n    submission_df.to_csv(SUBMISSION_FILE, index=False)\n    print(f\"笨 Submission file saved to {SUBMISSION_FILE}\")\n\nmain()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-11T12:03:47.581833Z","iopub.execute_input":"2026-01-11T12:03:47.582497Z","iopub.status.idle":"2026-01-11T12:53:38.632952Z","shell.execute_reply.started":"2026-01-11T12:03:47.582468Z","shell.execute_reply":"2026-01-11T12:53:38.631863Z"}},"outputs":[{"name":"stdout","text":"PyTorch confirmed CUDA is available. Using device: CUDA\n\nStep 1: Loading data...\nTrain shape: (75000, 4), Test shape: (75000, 3)\n\nStep 2: Preprocessing price column for RoBERTa training...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/numpy/lib/_function_base_impl.py:4968: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n","output_type":"stream"},{"name":"stdout","text":"Price column transformed and binned into 14 classes.\n\nStep 3: Fine-tuning RoBERTa for price classification...\nFound existing RoBERTa model. Skipping training.\n\nStep 4: Generating price class predictions from RoBERTa (with caching)...\n泅 Running RoBERTa inference for train_roberta_preds (this may take time)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='9375' max='9375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [9375/9375 06:49]\n    </div>\n    "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    "},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_107/4034249665.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"笨 Submission file saved to {SUBMISSION_FILE}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_107/4034249665.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nStep 4: Generating price class predictions from RoBERTa (with caching)...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     train_df[\"roberta_pred_class\"] = get_roberta_predictions_with_cache(\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mTEXT_COLUMN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_107/1062449484.py\u001b[0m in \u001b[0;36mget_roberta_predictions_with_cache\u001b[0;34m(df, text_col, cache_name)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"泅 Running RoBERTa inference for {cache_name} (this may take time)...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_with_roberta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_107/2810908536.py\u001b[0m in \u001b[0;36mpredict_with_roberta\u001b[0;34m(df, text_col)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;31m# Return the class with the highest probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4582\u001b[0m         )\n\u001b[1;32m   4583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4584\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4585\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_memory_tracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_and_update_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer_callback.py\u001b[0m in \u001b[0;36mon_predict\u001b[0;34m(self, args, state, control, metrics)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerControl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_predict\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainerControl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer_callback.py\u001b[0m in \u001b[0;36mcall_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             result = getattr(callback, event)(\n\u001b[0m\u001b[1;32m    557\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/integrations/integration_utils.py\u001b[0m in \u001b[0;36mon_predict\u001b[0;34m(self, args, state, control, metrics, **kwargs)\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_world_process_zero\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewrite_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/integrations/integration_utils.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, args, state, model, **kwargs)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m                 self._wandb.init(\n\u001b[0m\u001b[1;32m    894\u001b[0m                     \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"WANDB_PROJECT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"huggingface\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0minit_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(entity, project, dir, id, name, notes, tags, config, config_exclude_keys, config_include_keys, allow_val_change, group, job_type, mode, force, anonymous, reinit, resume, resume_from, fork_from, save_code, tensorboard, sync_tensorboard, monitor_gym, settings)\u001b[0m\n\u001b[1;32m   1521\u001b[0m         \u001b[0mwi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_WandbInit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_telemetry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1523\u001b[0;31m         \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1524\u001b[0m         \u001b[0mrun_settings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_warnings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_run_settings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36mmaybe_login\u001b[0;34m(self, init_settings)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         wandb_login._login(\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0manonymous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manonymous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36m_login\u001b[0;34m(anonymous, key, relogin, host, force, timeout, verify, referrer, update_api_key, _silent, _disable_warning)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mkey_is_pre_configured\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwlogin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferrer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreferrer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36mprompt_api_key\u001b[0;34m(self, referrer)\u001b[0m\n\u001b[1;32m    236\u001b[0m     ) -> Tuple[Optional[str], ApiKeyStatus]:\n\u001b[1;32m    237\u001b[0m         \u001b[0;34m\"\"\"Updates the global API key by prompting the user.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prompt_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferrer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mApiKeyStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOTTY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             directive = (\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36m_prompt_api_key\u001b[0;34m(self, referrer)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                 key = apikey.prompt_api_key(\n\u001b[0m\u001b[1;32m    215\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                     \u001b[0mapi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/lib/apikey.py\u001b[0m in \u001b[0;36mprompt_api_key\u001b[0;34m(settings, api, input_callback, browser_callback, no_offline, no_create, local, referrer)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mjupyter\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"google.colab\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mlog_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOG_STRING_NOCOLOR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjupyter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattempt_colab_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapp_url\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mkey\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/jupyter.py\u001b[0m in \u001b[0;36mattempt_colab_login\u001b[0;34m(app_url, referrer)\u001b[0m\n\u001b[1;32m    352\u001b[0m     )\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_wandbApiKey\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":39}]}