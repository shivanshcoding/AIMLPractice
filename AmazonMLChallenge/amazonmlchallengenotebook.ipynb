{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74a2fc95",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-12T11:41:43.828341Z",
     "iopub.status.busy": "2026-01-12T11:41:43.827895Z",
     "iopub.status.idle": "2026-01-12T11:41:44.617588Z",
     "shell.execute_reply": "2026-01-12T11:41:44.616297Z"
    },
    "papermill": {
     "duration": 0.796572,
     "end_time": "2026-01-12T11:41:44.619401",
     "exception": false,
     "start_time": "2026-01-12T11:41:43.822829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/models/pytorch/models-by-shivansh/1/lgbm_regressor.pkl\n",
      "/kaggle/input/models/pytorch/models-by-shivansh/1/price_processor.joblib\n",
      "/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/config.json\n",
      "/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/merges.txt\n",
      "/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/training_args.bin\n",
      "/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/vocab.json\n",
      "/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/tokenizer_config.json\n",
      "/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/model.safetensors\n",
      "/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/special_tokens_map.json\n",
      "/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-1172/config.json\n",
      "/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-1172/trainer_state.json\n",
      "/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-1172/training_args.bin\n",
      "/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-1172/scaler.pt\n",
      "/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-1172/scheduler.pt\n",
      "/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-1172/model.safetensors\n",
      "/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-1172/optimizer.pt\n",
      "/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-1172/rng_state.pth\n",
      "/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-2344/config.json\n",
      "/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-2344/trainer_state.json\n",
      "/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-2344/training_args.bin\n",
      "/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-2344/scaler.pt\n",
      "/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-2344/scheduler.pt\n",
      "/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-2344/model.safetensors\n",
      "/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-2344/optimizer.pt\n",
      "/kaggle/input/models/pytorch/models-by-shivansh/1/roberta_classifier/checkpoint-2344/rng_state.pth\n",
      "/kaggle/input/amazon-ml-challenge/sample_test.csv\n",
      "/kaggle/input/amazon-ml-challenge/sample_test_out.csv\n",
      "/kaggle/input/amazon-ml-challenge/evaluation.py\n",
      "/kaggle/input/amazon-ml-challenge/train.csv\n",
      "/kaggle/input/amazon-ml-challenge/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6089489c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T11:41:44.626716Z",
     "iopub.status.busy": "2026-01-12T11:41:44.626366Z",
     "iopub.status.idle": "2026-01-12T11:42:22.797306Z",
     "shell.execute_reply": "2026-01-12T11:42:22.796557Z"
    },
    "papermill": {
     "duration": 38.176705,
     "end_time": "2026-01-12T11:42:22.799242",
     "exception": false,
     "start_time": "2026-01-12T11:41:44.622537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sqlalchemy/orm/query.py:195: SyntaxWarning: \"is not\" with 'tuple' literal. Did you mean \"!=\"?\n",
      "  if entities is not ():\n",
      "2026-01-12 11:42:06.811834: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1768218127.011198      24 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1768218127.067571      24 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1768218127.569995      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768218127.570045      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768218127.570048      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1768218127.570051      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import scipy, transformers, accelerate, sklearn, joblib, re, os\n",
    "from scipy import stats\n",
    "from scipy.stats.mstats import winsorize\n",
    "import lightgbm as lgb\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d1c0321",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T11:42:22.808234Z",
     "iopub.status.busy": "2026-01-12T11:42:22.807211Z",
     "iopub.status.idle": "2026-01-12T11:42:51.402789Z",
     "shell.execute_reply": "2026-01-12T11:42:51.401958Z"
    },
    "papermill": {
     "duration": 28.601504,
     "end_time": "2026-01-12T11:42:51.404332",
     "exception": false,
     "start_time": "2026-01-12T11:42:22.802828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "笨 Models copied to writable directory\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "SRC_MODEL_DIR = \"/kaggle/input/models/pytorch/models-by-shivansh/1\"\n",
    "DST_MODEL_DIR = \"/kaggle/working/models\"\n",
    "\n",
    "os.makedirs(DST_MODEL_DIR, exist_ok=True)\n",
    "\n",
    "for item in os.listdir(SRC_MODEL_DIR):\n",
    "    src = os.path.join(SRC_MODEL_DIR, item)\n",
    "    dst = os.path.join(DST_MODEL_DIR, item)\n",
    "\n",
    "    if os.path.isdir(src):\n",
    "        shutil.copytree(src, dst, dirs_exist_ok=True)\n",
    "    else:\n",
    "        shutil.copy2(src, dst)\n",
    "\n",
    "print(\"笨 Models copied to writable directory\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73029b88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T11:42:51.411972Z",
     "iopub.status.busy": "2026-01-12T11:42:51.411460Z",
     "iopub.status.idle": "2026-01-12T11:45:12.845431Z",
     "shell.execute_reply": "2026-01-12T11:45:12.844430Z"
    },
    "papermill": {
     "duration": 141.440169,
     "end_time": "2026-01-12T11:45:12.847660",
     "exception": false,
     "start_time": "2026-01-12T11:42:51.407491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.8.0+cu126\r\n",
      "Uninstalling torch-2.8.0+cu126:\r\n",
      "  Successfully uninstalled torch-2.8.0+cu126\r\n",
      "Found existing installation: torchvision 0.23.0+cu126\r\n",
      "Uninstalling torchvision-0.23.0+cu126:\r\n",
      "  Successfully uninstalled torchvision-0.23.0+cu126\r\n",
      "Found existing installation: torchaudio 2.8.0+cu126\r\n",
      "Uninstalling torchaudio-2.8.0+cu126:\r\n",
      "  Successfully uninstalled torchaudio-2.8.0+cu126\r\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu121\r\n",
      "Collecting torch==2.2.2\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torch-2.2.2%2Bcu121-cp312-cp312-linux_x86_64.whl (757.2 MB)\r\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m757.2/757.2 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting torchvision==0.17.2\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.17.2%2Bcu121-cp312-cp312-linux_x86_64.whl (7.0 MB)\r\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting torchaudio==2.2.2\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.2.2%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\r\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (3.20.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (4.15.0)\r\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (2025.10.0)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\r\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\r\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\r\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\r\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\r\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\r\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\r\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\r\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\r\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\r\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\r\n",
      "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.17.2) (2.0.2)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.17.2) (11.3.0)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2) (12.6.85)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.2.2) (3.0.3)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.2.2) (1.3.0)\r\n",
      "Installing collected packages: nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\r\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\r\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.6.77\r\n",
      "    Uninstalling nvidia-nvtx-cu12-12.6.77:\r\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\r\n",
      "  Attempting uninstall: nvidia-nccl-cu12\r\n",
      "    Found existing installation: nvidia-nccl-cu12 2.27.3\r\n",
      "    Uninstalling nvidia-nccl-cu12-2.27.3:\r\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.7.77\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.7.77:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.2+cu121 torchaudio-2.2.2+cu121 torchvision-0.17.2+cu121\r\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y torch torchvision torchaudio\n",
    "!pip install torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 \\\n",
    "  --index-url https://download.pytorch.org/whl/cu121\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5c4d6d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T11:45:12.907697Z",
     "iopub.status.busy": "2026-01-12T11:45:12.907380Z",
     "iopub.status.idle": "2026-01-12T11:45:12.912881Z",
     "shell.execute_reply": "2026-01-12T11:45:12.912067Z"
    },
    "papermill": {
     "duration": 0.037086,
     "end_time": "2026-01-12T11:45:12.914131",
     "exception": false,
     "start_time": "2026-01-12T11:45:12.877045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu126\n",
      "12.6\n",
      "True\n",
      "Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87484f78",
   "metadata": {
    "papermill": {
     "duration": 0.028651,
     "end_time": "2026-01-12T11:45:12.971646",
     "exception": false,
     "start_time": "2026-01-12T11:45:12.942995",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "659ad241",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T11:45:13.030915Z",
     "iopub.status.busy": "2026-01-12T11:45:13.030625Z",
     "iopub.status.idle": "2026-01-12T11:45:13.037114Z",
     "shell.execute_reply": "2026-01-12T11:45:13.036454Z"
    },
    "papermill": {
     "duration": 0.038457,
     "end_time": "2026-01-12T11:45:13.038570",
     "exception": false,
     "start_time": "2026-01-12T11:45:13.000113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- File Paths ---\n",
    "DATA_DIR = \"/kaggle/input/amazon-ml-challenge/\"\n",
    "TRAIN_FILE = f\"{DATA_DIR}train.csv\"\n",
    "TEST_FILE = f\"{DATA_DIR}test.csv\"\n",
    "MODEL_DIR = \"/kaggle/working/models/\"\n",
    "SUBMISSION_FILE = \"/kaggle/working/submission.csv\"\n",
    "\n",
    "# --- Preprocessing ---\n",
    "PRICE_COLUMN = \"price\"\n",
    "TEXT_COLUMN = \"catalog_content\"\n",
    "TARGET_CLASS_COLUMN = \"price_class\"\n",
    "NUM_PRICE_CLASSES = 14\n",
    "\n",
    "# --- RoBERTa Model ---\n",
    "ROBERTA_MODEL_NAME = \"roberta-base\"\n",
    "ROBERTA_MODEL_PATH = f\"{MODEL_DIR}roberta_classifier\"\n",
    "ROBERTA_BATCH_SIZE = 64      # Increased for speed\n",
    "ROBERTA_EPOCHS = 2           # Reduced, often sufficient\n",
    "ROBERTA_LEARNING_RATE = 2e-5\n",
    "\n",
    "# --- Ensemble Model (LightGBM) ---\n",
    "ENSEMBLE_MODEL_PATH = f\"{MODEL_DIR}lgbm_regressor.pkl\"\n",
    "LGBM_PARAMS = {\n",
    "    'objective': 'regression_l1', 'metric': 'mae', 'n_estimators': 2000,\n",
    "    'learning_rate': 0.01, 'feature_fraction': 0.8, 'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.1,\n",
    "    'num_leaves': 31, 'verbose': -1, 'n_jobs': -1,\n",
    "}\n",
    "SVM_PARAMS = {'kernel': 'rbf', 'C': 1.0, 'epsilon': 0.1}\n",
    "DT_PARAMS = {'max_depth': 10, 'min_samples_split': 5}\n",
    "ADABOOST_PARAMS = {'n_estimators': 50, 'learning_rate': 1.0}\n",
    "VOTING_WEIGHTS = [0.3, 0.3, 0.4] # Adjust these based on your preference\n",
    "\n",
    "# --- General ---\n",
    "RANDOM_STATE = 42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ce76e6",
   "metadata": {
    "papermill": {
     "duration": 0.028884,
     "end_time": "2026-01-12T11:45:13.096558",
     "exception": false,
     "start_time": "2026-01-12T11:45:13.067674",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Data PreProcessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37b38c6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T11:45:13.156854Z",
     "iopub.status.busy": "2026-01-12T11:45:13.156172Z",
     "iopub.status.idle": "2026-01-12T11:45:13.172788Z",
     "shell.execute_reply": "2026-01-12T11:45:13.172207Z"
    },
    "papermill": {
     "duration": 0.048331,
     "end_time": "2026-01-12T11:45:13.174336",
     "exception": false,
     "start_time": "2026-01-12T11:45:13.126005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----------------- Feature Engineering (from your provided code) -----------------\n",
    "weight_units = {'g','gram','grams','gramm','gr','kg','k','lb','pound','pounds','oz','ounce','ounces'}\n",
    "volume_units = {'ml','millilitre','milliliter','mililitro','ltr','liter','liters','l','fl oz','fluid ounce','fluid ounces','fluid ounces'}\n",
    "count_units  = {'count','ct','each','unit','units','pack','packs','piece','pieces','box','bottle','bottles','bag','bags','case','carton','capsule','jar','pouch','bucket','tea bags','paper cupcake liners'}\n",
    "length_units = {'cm','mm','m','meter','meters','inch','inches','in','ft','foot','feet'}\n",
    "\n",
    "def extract_value_unit(text):\n",
    "    lines = [l.strip() for l in str(text).split(\"\\n\") if l.strip()]\n",
    "    if len(lines) < 2:\n",
    "        return pd.Series([None, None])\n",
    "    value_line = lines[-2]\n",
    "    unit_line = lines[-1]\n",
    "    match_val = re.search(r\"[\\d\\.]+\", value_line)\n",
    "    value = float(match_val.group()) if match_val else None\n",
    "    unit = re.sub(r'Unit[s]?:\\s*', '', unit_line, flags=re.IGNORECASE).strip()\n",
    "    return pd.Series([value, unit])\n",
    "\n",
    "def extract_ipq(text):\n",
    "    patterns = [r'pack of (\\d+)', r'(\\d+)\\s*count', r'box of (\\d+)', r'case of (\\d+)', r'(\\d+)\\s*pieces', r'(\\d+)\\s*units', r'(\\d+)\\s*ct', r'(\\d+)\\s*each']\n",
    "    text_lower = str(text).lower()\n",
    "    for pat in patterns:\n",
    "        match = re.search(pat, text_lower)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "    return 1\n",
    "\n",
    "def map_unit_class(unit):\n",
    "    if unit is None: return 'others'\n",
    "    u = unit.strip().lower()\n",
    "    if u in weight_units: return 'weight'\n",
    "    if u in volume_units: return 'volume'\n",
    "    if u in count_units: return 'count'\n",
    "    if u in length_units: return 'length'\n",
    "    return 'others'\n",
    "\n",
    "def convert_to_standard(value, unit):\n",
    "    if value is None or unit is None: return value\n",
    "    u = unit.strip().lower()\n",
    "    if u in {'oz', 'ounce', 'ounces'}: return value * 28.3495\n",
    "    if u in {'lb', 'pound', 'pounds'}: return value * 453.592\n",
    "    if u in {'kg', 'k'}: return value * 1000\n",
    "    if u in {'g', 'gram', 'grams', 'gramm', 'gr'}: return value\n",
    "    if u in {'ltr', 'liter', 'liters', 'l'}: return value * 1000\n",
    "    if u in {'fl oz', 'fluid ounce', 'fluid ounces'}: return value * 29.5735\n",
    "    if u in {'ml', 'millilitre', 'milliliter', 'mililitro'}: return value\n",
    "    if u in {'cm'}: return value / 100\n",
    "    if u in {'mm'}: return value / 1000\n",
    "    if u in {'inch', 'inches', 'in'}: return value * 0.0254\n",
    "    if u in {'ft', 'foot', 'feet'}: return value * 0.3048\n",
    "    if u in {'m', 'meter', 'meters'}: return value\n",
    "    if u in count_units: return value\n",
    "    return value\n",
    "\n",
    "def engineer_features(df):\n",
    "    \"\"\"Applies all feature engineering steps.\"\"\"\n",
    "    temp_df = df.copy()\n",
    "    temp_df[['value', 'unit']] = temp_df['catalog_content'].apply(extract_value_unit)\n",
    "    temp_df['IPQ'] = temp_df['catalog_content'].apply(extract_ipq)\n",
    "    temp_df['standardised_units'] = temp_df['unit'].apply(map_unit_class)\n",
    "    temp_df['updated_values'] = temp_df.apply(lambda row: convert_to_standard(row['value'], row['unit']), axis=1)\n",
    "    \n",
    "    # Fill NaNs created during feature engineering\n",
    "    temp_df['updated_values'] = temp_df['updated_values'].fillna(temp_df['updated_values'].median())\n",
    "    temp_df['IPQ'] = temp_df['IPQ'].fillna(1)\n",
    "    \n",
    "    # One-hot encode and ensure all possible columns are present\n",
    "    unit_dummies = pd.get_dummies(temp_df['standardised_units'], prefix='unit')\n",
    "    for col in ['unit_weight', 'unit_volume', 'unit_count', 'unit_length', 'unit_others']:\n",
    "        if col not in unit_dummies.columns:\n",
    "            unit_dummies[col] = 0\n",
    "    temp_df = pd.concat([temp_df, unit_dummies], axis=1)\n",
    "    \n",
    "    return temp_df\n",
    "\n",
    "# ----------------- Price Transformation Pipeline -----------------\n",
    "\n",
    "class PriceProcessor:\n",
    "    \"\"\"Handles Box-Cox, Winsorization, and Binning for the price column.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.lambda_ = None\n",
    "        self.winsor_limits = (0.01, 0.01) # Winsorize 1% from both tails\n",
    "        self.bin_edges = None\n",
    "        self.path = os.path.join(MODEL_DIR, \"price_processor.joblib\")\n",
    "\n",
    "    def fit_transform(self, price_series):\n",
    "        # 1. Box-Cox Transform (add 1 to handle prices <= 0)\n",
    "        transformed_price, self.lambda_ = stats.boxcox(price_series + 1)\n",
    "        \n",
    "        # 2. Winsorization\n",
    "        winsorized_price = winsorize(transformed_price, limits=self.winsor_limits)\n",
    "        \n",
    "        # 3. Binning into classes\n",
    "        binned_price, self.bin_edges = pd.qcut(\n",
    "            winsorized_price, \n",
    "            q=NUM_PRICE_CLASSES, \n",
    "            labels=False, \n",
    "            retbins=True, \n",
    "            duplicates='drop'\n",
    "        )\n",
    "        self.save()\n",
    "        return binned_price\n",
    "\n",
    "    def save(self):\n",
    "        os.makedirs(os.path.dirname(self.path), exist_ok=True)\n",
    "        joblib.dump(self, self.path)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls):\n",
    "        return joblib.load(os.path.join(MODEL_DIR, \"price_processor.joblib\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481c51db",
   "metadata": {
    "papermill": {
     "duration": 0.028503,
     "end_time": "2026-01-12T11:45:13.232813",
     "exception": false,
     "start_time": "2026-01-12T11:45:13.204310",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a6c7639",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T11:45:13.291917Z",
     "iopub.status.busy": "2026-01-12T11:45:13.291405Z",
     "iopub.status.idle": "2026-01-12T11:45:13.295634Z",
     "shell.execute_reply": "2026-01-12T11:45:13.294998Z"
    },
    "papermill": {
     "duration": 0.035509,
     "end_time": "2026-01-12T11:45:13.296952",
     "exception": false,
     "start_time": "2026-01-12T11:45:13.261443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def smape(y_true, y_pred):\n",
    "    # Calculates the Symmetric Mean Absolute Percentage Error (SMAPE).\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    \n",
    "    # Handle the case where both true and pred are zero\n",
    "    # to avoid division by zero\n",
    "    ratio = np.where(denominator == 0, 0, numerator / denominator)\n",
    "    \n",
    "    return np.mean(ratio) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba1c59b",
   "metadata": {
    "papermill": {
     "duration": 0.029095,
     "end_time": "2026-01-12T11:45:13.355869",
     "exception": false,
     "start_time": "2026-01-12T11:45:13.326774",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Ensemble Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f4e0a3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T11:45:13.415938Z",
     "iopub.status.busy": "2026-01-12T11:45:13.415233Z",
     "iopub.status.idle": "2026-01-12T11:45:13.435885Z",
     "shell.execute_reply": "2026-01-12T11:45:13.435173Z"
    },
    "papermill": {
     "duration": 0.052546,
     "end_time": "2026-01-12T11:45:13.437515",
     "exception": false,
     "start_time": "2026-01-12T11:45:13.384969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, VotingRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def get_feature_columns(df):\n",
    "    \"\"\"Identifies the feature columns for the ensemble model.\"\"\"\n",
    "    exclude_cols = [\n",
    "        'sample_id', 'catalog_content', 'image_link', 'price',\n",
    "        'price_class', 'value', 'unit', 'standardised_units'\n",
    "    ]\n",
    "    feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "    # print(f\"DEBUG: Selected {len(feature_cols)} numeric features: {feature_cols}\")\n",
    "    return feature_cols\n",
    "\n",
    "def train_ensemble_model(df, target_col):\n",
    "    \"\"\"Trains and saves the Voting Regressor model (SVR + DecisionTree + AdaBoost).\"\"\"\n",
    "    train_split, val_split = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    \n",
    "    feature_cols = get_feature_columns(df)\n",
    "    X_train = train_split[feature_cols]\n",
    "    y_train = train_split[target_col]\n",
    "\n",
    "    X_val = val_split[feature_cols]\n",
    "    y_val = val_split[target_col]\n",
    "\n",
    "    # Base learners\n",
    "    svr = make_pipeline(StandardScaler(), SVR(**SVM_PARAMS))\n",
    "    dtr = DecisionTreeRegressor(random_state=RANDOM_STATE, **DT_PARAMS)\n",
    "    ada = AdaBoostRegressor(random_state=RANDOM_STATE, **ADABOOST_PARAMS)\n",
    "\n",
    "    # Voting ensemble\n",
    "    model = VotingRegressor(\n",
    "        estimators=[\n",
    "            (\"svr\", svr),\n",
    "            (\"dt\", dtr),\n",
    "            (\"ada\", ada),\n",
    "        ],\n",
    "        weights=VOTING_WEIGHTS,\n",
    "        n_jobs=None,  # VotingRegressor in sklearn doesn't support n_jobs (only in some versions for estimators); keep None\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    val_predictions = model.predict(X_val)\n",
    "    train_predictions = model.predict(X_train)\n",
    "\n",
    "    score_train = smape(y_train,train_predictions)\n",
    "    score_val = smape(y_val, val_predictions)\n",
    "    \n",
    "    print(f\"\\n沒 Validation SMAPE Score: {score_val:.4f}%\")\n",
    "    print(f\"\\n沒 Training SMAPE Score: {score_train:.4f}%\")\n",
    "    print(\"----------------------------------------------\\n\")\n",
    "\n",
    "    # Save the model\n",
    "    os.makedirs(os.path.dirname(ENSEMBLE_MODEL_PATH), exist_ok=True)\n",
    "    joblib.dump(model, ENSEMBLE_MODEL_PATH)\n",
    "    print(f\"Ensemble model saved to {ENSEMBLE_MODEL_PATH}\")\n",
    "    return model\n",
    "\n",
    "def predict_with_ensemble_model(df):\n",
    "    \"\"\"Loads and predicts with the saved Voting Regressor model.\"\"\"\n",
    "    feature_cols = get_feature_columns(df)\n",
    "    X_test = df[feature_cols]\n",
    "\n",
    "    model = joblib.load(ENSEMBLE_MODEL_PATH)\n",
    "    predictions = model.predict(X_test)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74596985",
   "metadata": {
    "papermill": {
     "duration": 0.031535,
     "end_time": "2026-01-12T11:45:13.499911",
     "exception": false,
     "start_time": "2026-01-12T11:45:13.468376",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Roberta Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe7f4672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T11:45:13.560743Z",
     "iopub.status.busy": "2026-01-12T11:45:13.560410Z",
     "iopub.status.idle": "2026-01-12T11:45:13.573605Z",
     "shell.execute_reply": "2026-01-12T11:45:13.573027Z"
    },
    "papermill": {
     "duration": 0.046006,
     "end_time": "2026-01-12T11:45:13.575300",
     "exception": false,
     "start_time": "2026-01-12T11:45:13.529294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PriceDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.texts[item])\n",
    "        label = self.labels[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def train_roberta(train_df, text_col, target_col):\n",
    "    \"\"\"Fine-tunes and saves the RoBERTa model.\"\"\"\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(ROBERTA_MODEL_NAME)\n",
    "    model = RobertaForSequenceClassification.from_pretrained(\n",
    "        ROBERTA_MODEL_NAME,\n",
    "        num_labels=train_df[target_col].nunique()\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    train_dataset = PriceDataset(\n",
    "        texts=train_df[text_col].to_numpy(),\n",
    "        labels=train_df[target_col].to_numpy(),\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=ROBERTA_MODEL_PATH,\n",
    "        num_train_epochs=ROBERTA_EPOCHS,\n",
    "        per_device_train_batch_size=ROBERTA_BATCH_SIZE,\n",
    "        learning_rate=ROBERTA_LEARNING_RATE,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=100,\n",
    "        do_train=True,\n",
    "        do_eval=False,\n",
    "        save_strategy=\"epoch\",\n",
    "        fp16=True,  # Mixed-precision for speed\n",
    "        load_best_model_at_end=False,\n",
    "        seed=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.save_model(ROBERTA_MODEL_PATH)\n",
    "    tokenizer.save_pretrained(ROBERTA_MODEL_PATH)\n",
    "    print(f\"RoBERTa model saved to {ROBERTA_MODEL_PATH}\")\n",
    "\n",
    "import gc\n",
    "\n",
    "def predict_with_roberta(df, text_col, chunk_size=5000):\n",
    "    \"\"\"\n",
    "    Optimized prediction:\n",
    "    1. Uses FP16 and Batch Size 64 (Speed).\n",
    "    2. Processes in chunks to prevent OOM (Memory).\n",
    "    3. Clears cache aggressively.\n",
    "    \"\"\"\n",
    "    print(f\"沐 Initializing Inference on {len(df)} rows...\")\n",
    "    \n",
    "    tokenizer = RobertaTokenizer.from_pretrained(ROBERTA_MODEL_PATH)\n",
    "    model = RobertaForSequenceClassification.from_pretrained(ROBERTA_MODEL_PATH).to(DEVICE)\n",
    "    \n",
    "    # optimized arguments for inference\n",
    "    test_args = TrainingArguments(\n",
    "        output_dir=os.path.join(MODEL_DIR, \"inference_temp\"),\n",
    "        per_device_eval_batch_size=64,   # Match your training batch size\n",
    "        fp16=True,                       # Much faster, less memory\n",
    "        dataloader_num_workers=2,        # Speed up data loading\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(model=model, args=test_args)\n",
    "    \n",
    "    all_predictions = []\n",
    "    \n",
    "    # Process in chunks to avoid RAM explosion\n",
    "    total_chunks = (len(df) // chunk_size) + 1\n",
    "    \n",
    "    for i in range(0, len(df), chunk_size):\n",
    "        chunk_df = df.iloc[i : i + chunk_size]\n",
    "        \n",
    "        if chunk_df.empty:\n",
    "            continue\n",
    "            \n",
    "        print(f\"   Processing chunk {i//chunk_size + 1}/{total_chunks} ({len(chunk_df)} rows)...\")\n",
    "        \n",
    "        # Create dataset just for this chunk\n",
    "        chunk_dataset = PriceDataset(\n",
    "            texts=chunk_df[text_col].to_numpy(),\n",
    "            labels=np.zeros(len(chunk_df)), # Dummy labels\n",
    "            tokenizer=tokenizer\n",
    "        )\n",
    "        \n",
    "        # Predict\n",
    "        predictions = trainer.predict(chunk_dataset).predictions\n",
    "        \n",
    "        # Get class indices and append to list\n",
    "        chunk_preds = np.argmax(predictions, axis=1)\n",
    "        all_predictions.append(chunk_preds)\n",
    "        \n",
    "        # CRITICAL: Free memory\n",
    "        del chunk_dataset, predictions, chunk_preds\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "    print(\"笨 Inference complete.\")\n",
    "    return np.concatenate(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb2143ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T11:45:13.635804Z",
     "iopub.status.busy": "2026-01-12T11:45:13.635507Z",
     "iopub.status.idle": "2026-01-12T11:45:13.640386Z",
     "shell.execute_reply": "2026-01-12T11:45:13.639785Z"
    },
    "papermill": {
     "duration": 0.036856,
     "end_time": "2026-01-12T11:45:13.641765",
     "exception": false,
     "start_time": "2026-01-12T11:45:13.604909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_roberta_predictions_with_cache(\n",
    "    df,\n",
    "    text_col,\n",
    "    cache_name,\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes RoBERTa predictions once and caches them.\n",
    "    On reruns, loads directly from disk.\n",
    "    \"\"\"\n",
    "    CACHE_DIR = \"/kaggle/working/roberta_cache\"\n",
    "    os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "    cache_path = os.path.join(CACHE_DIR, f\"{cache_name}.npy\")\n",
    "\n",
    "    if os.path.exists(cache_path):\n",
    "        print(f\"笨 Loading cached RoBERTa predictions from {cache_path}\")\n",
    "        return np.load(cache_path)\n",
    "\n",
    "    print(f\"泅 Running RoBERTa inference for {cache_name} (this may take time)...\")\n",
    "    preds = predict_with_roberta(df, text_col)\n",
    "\n",
    "    np.save(cache_path, preds)\n",
    "    print(f\"汳ｾ Saved RoBERTa predictions to {cache_path}\")\n",
    "\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e367e002",
   "metadata": {
    "papermill": {
     "duration": 0.029183,
     "end_time": "2026-01-12T11:45:13.701279",
     "exception": false,
     "start_time": "2026-01-12T11:45:13.672096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Main**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cdbd41d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T11:45:13.760983Z",
     "iopub.status.busy": "2026-01-12T11:45:13.760688Z",
     "iopub.status.idle": "2026-01-12T11:45:34.278660Z",
     "shell.execute_reply": "2026-01-12T11:45:34.277620Z"
    },
    "papermill": {
     "duration": 20.549639,
     "end_time": "2026-01-12T11:45:34.280182",
     "exception": false,
     "start_time": "2026-01-12T11:45:13.730543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch confirmed CUDA is available. Using device: CUDA\n",
      "\n",
      "Step 1: Loading data...\n",
      "Train shape: (2000, 4), Test shape: (2000, 3)\n",
      "\n",
      "Step 2: Preprocessing price column for RoBERTa training...\n",
      "Price column transformed and binned into 14 classes.\n",
      "\n",
      "Step 3: Fine-tuning RoBERTa for price classification...\n",
      "Found existing RoBERTa model. Skipping training.\n",
      "\n",
      "Step 4: Generating price class predictions from RoBERTa (with caching)...\n",
      "沐 Initializing Inference on 2000 rows...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/numpy/lib/_function_base_impl.py:4968: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n",
      "  arr.partition(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Processing chunk 1/1 (2000 rows)...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "笨 Inference complete.\n",
      "沐 Initializing Inference on 2000 rows...\n",
      "   Processing chunk 1/1 (2000 rows)...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "笨 Inference complete.\n",
      "笨 RoBERTa predictions added as features.\n",
      "\n",
      "Step 5: Engineering features from catalog_content...\n",
      "Feature engineering complete.\n",
      "\n",
      "Step 6: Training the final LightGBM ensemble model...\n",
      "\n",
      "沒 Validation SMAPE Score: 53.1322%\n",
      "\n",
      "沒 Training SMAPE Score: 51.9080%\n",
      "----------------------------------------------\n",
      "\n",
      "Ensemble model saved to /kaggle/working/models/lgbm_regressor.pkl\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    #--- 0. CRITICAL: Verify GPU is available ---\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "        print(\"!!! ERROR: No CUDA-enabled GPU found !!!\")\n",
    "        print(\"!!!       Aborting training.       !!!\")\n",
    "        print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "        return\n",
    "    print(f\"PyTorch confirmed CUDA is available. Using device: {DEVICE.upper()}\")\n",
    "    \n",
    "    # --- 1. Load Data ---\n",
    "    print(\"\\nStep 1: Loading data...\")\n",
    "    train_df = pd.read_csv(TRAIN_FILE, nrows = 2000)\n",
    "    test_df = pd.read_csv(TEST_FILE, nrows = 2000)\n",
    "    print(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")\n",
    "\n",
    "    # --- 2. Preprocess Price Column for Training ---\n",
    "    print(\"\\nStep 2: Preprocessing price column for RoBERTa training...\")\n",
    "    price_processor = PriceProcessor()\n",
    "    train_df[TARGET_CLASS_COLUMN] = price_processor.fit_transform(train_df[PRICE_COLUMN])\n",
    "    print(f\"Price column transformed and binned into {train_df[TARGET_CLASS_COLUMN].nunique()} classes.\")\n",
    "\n",
    "    # --- 3. Fine-Tune RoBERTa Classifier ---\n",
    "    print(\"\\nStep 3: Fine-tuning RoBERTa for price classification...\")\n",
    "    model_config_path = os.path.join(ROBERTA_MODEL_PATH, \"config.json\")\n",
    "    if not os.path.exists(model_config_path):\n",
    "        print(\"RoBERTa model not found. Starting training...\")\n",
    "        train_roberta(train_df, TEXT_COLUMN, TARGET_CLASS_COLUMN)\n",
    "    else:\n",
    "        print(\"Found existing RoBERTa model. Skipping training.\")\n",
    "\n",
    "    # --- 4. Get RoBERTa Predictions as Features ---\n",
    "    print(\"\\nStep 4: Generating price class predictions from RoBERTa (with caching)...\")\n",
    "\n",
    "    train_df['roberta_pred_class'] = predict_with_roberta(train_df, TEXT_COLUMN)\n",
    "    test_df['roberta_pred_class'] = predict_with_roberta(test_df, TEXT_COLUMN)\n",
    "\n",
    "    print(\"笨 RoBERTa predictions added as features.\")\n",
    "\n",
    "    # --- 5. Engineer Additional Features ---\n",
    "    print(\"\\nStep 5: Engineering features from catalog_content...\")\n",
    "    train_df_featured = engineer_features(train_df)\n",
    "    test_df_featured = engineer_features(test_df)\n",
    "    print(\"Feature engineering complete.\")\n",
    "\n",
    "    # --- 6. Train Ensemble Model ---\n",
    "    print(\"\\nStep 6: Training the final LightGBM ensemble model...\")\n",
    "    train_ensemble_model(train_df_featured, PRICE_COLUMN)\n",
    "\n",
    "    # flag = input(\"Do you want to use this model for test predictions?(Y/N) : \")\n",
    "    # if(flag in 'Nn'):\n",
    "    #     return\n",
    "    return\n",
    "    # --- 7. Make Final Price Predictions ---\n",
    "    print(\"\\nStep 7: Making final price predictions on the test set...\")\n",
    "    test_predictions = predict_with_ensemble_model(test_df_featured)\n",
    "    test_df['price'] = test_predictions\n",
    "\n",
    "    # --- 8. Save Results ---\n",
    "    # The evaluation step has been removed as test.csv does not have a 'price' column.\n",
    "    print(\"\\nStep 8: Saving submission file...\")\n",
    "    submission_df = test_df[['sample_id', 'price']]\n",
    "    submission_df.to_csv(SUBMISSION_FILE, index=False)\n",
    "    print(f\"笨 Submission file saved to {SUBMISSION_FILE}\")\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8454287,
     "sourceId": 14462962,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 557481,
     "modelInstanceId": 544398,
     "sourceId": 716170,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 236.152292,
   "end_time": "2026-01-12T11:45:37.430700",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-12T11:41:41.278408",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
